{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {64, 128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import common_utils\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "in a separate file called common_utils.py\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_3001_4001_phnd_neg_0000.wav</td>\n",
       "      <td>184.570312</td>\n",
       "      <td>623</td>\n",
       "      <td>69.222222</td>\n",
       "      <td>0.515281</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.669799</td>\n",
       "      <td>63.340282</td>\n",
       "      <td>1.811605</td>\n",
       "      <td>58.117188</td>\n",
       "      <td>-3.286546</td>\n",
       "      <td>54.268448</td>\n",
       "      <td>-2.719069</td>\n",
       "      <td>59.548176</td>\n",
       "      <td>-4.559987</td>\n",
       "      <td>70.774803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_3001_4001_phnd_neg_0001.wav</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "      <td>0.487201</td>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.542182</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.274423</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.666375</td>\n",
       "      <td>90.256195</td>\n",
       "      <td>1.573594</td>\n",
       "      <td>105.070496</td>\n",
       "      <td>-0.742024</td>\n",
       "      <td>82.417496</td>\n",
       "      <td>-1.961745</td>\n",
       "      <td>119.312355</td>\n",
       "      <td>1.513660</td>\n",
       "      <td>101.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_3001_4001_phnd_neg_0002.wav</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>1614</td>\n",
       "      <td>146.727273</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.442014</td>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.502390</td>\n",
       "      <td>73.079750</td>\n",
       "      <td>0.202623</td>\n",
       "      <td>72.040550</td>\n",
       "      <td>-4.021009</td>\n",
       "      <td>73.844353</td>\n",
       "      <td>-5.916223</td>\n",
       "      <td>103.834824</td>\n",
       "      <td>-2.939086</td>\n",
       "      <td>113.598824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_3001_4001_phnd_neg_0003.wav</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>2060</td>\n",
       "      <td>158.461538</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.257672</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.812989</td>\n",
       "      <td>93.791893</td>\n",
       "      <td>-0.429413</td>\n",
       "      <td>60.002579</td>\n",
       "      <td>-4.013513</td>\n",
       "      <td>82.544540</td>\n",
       "      <td>-5.858006</td>\n",
       "      <td>84.402092</td>\n",
       "      <td>0.686969</td>\n",
       "      <td>90.126389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_3001_4001_phnd_neg_0004.wav</td>\n",
       "      <td>75.999540</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>0.089313</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.584204</td>\n",
       "      <td>64.973305</td>\n",
       "      <td>0.744403</td>\n",
       "      <td>68.908516</td>\n",
       "      <td>-6.354805</td>\n",
       "      <td>66.414391</td>\n",
       "      <td>-6.555534</td>\n",
       "      <td>47.852840</td>\n",
       "      <td>-4.809713</td>\n",
       "      <td>73.033966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename       tempo  total_beats  average_beats  \\\n",
       "0  app_3001_4001_phnd_neg_0000.wav  184.570312          623      69.222222   \n",
       "1  app_3001_4001_phnd_neg_0001.wav  151.999081          521      74.428571   \n",
       "2  app_3001_4001_phnd_neg_0002.wav  112.347147         1614     146.727273   \n",
       "3  app_3001_4001_phnd_neg_0003.wav  107.666016         2060     158.461538   \n",
       "4  app_3001_4001_phnd_neg_0004.wav   75.999540           66      33.000000   \n",
       "\n",
       "   chroma_stft_mean  chroma_stft_var  chroma_cq_mean  chroma_cq_var  \\\n",
       "0          0.515281         0.093347        0.443441       0.082742   \n",
       "1          0.487201         0.094461        0.542182       0.073359   \n",
       "2          0.444244         0.099268        0.442014       0.083224   \n",
       "3          0.454156         0.100834        0.424370       0.084435   \n",
       "4          0.478780         0.100000        0.414859       0.089313   \n",
       "\n",
       "   chroma_cens_mean  chroma_cens_var  ...  mfcc15_mean  mfcc15_var  \\\n",
       "0          0.249143         0.021261  ...   -10.669799   63.340282   \n",
       "1          0.274423         0.008025  ...    -5.666375   90.256195   \n",
       "2          0.264430         0.013410  ...    -5.502390   73.079750   \n",
       "3          0.257672         0.016938  ...    -8.812989   93.791893   \n",
       "4          0.252143         0.019757  ...    -6.584204   64.973305   \n",
       "\n",
       "   mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  \\\n",
       "0     1.811605   58.117188    -3.286546   54.268448    -2.719069   59.548176   \n",
       "1     1.573594  105.070496    -0.742024   82.417496    -1.961745  119.312355   \n",
       "2     0.202623   72.040550    -4.021009   73.844353    -5.916223  103.834824   \n",
       "3    -0.429413   60.002579    -4.013513   82.544540    -5.858006   84.402092   \n",
       "4     0.744403   68.908516    -6.354805   66.414391    -6.555534   47.852840   \n",
       "\n",
       "   mfcc19_mean  mfcc19_var  \n",
       "0    -4.559987   70.774803  \n",
       "1     1.513660  101.014572  \n",
       "2    -2.939086  113.598824  \n",
       "3     0.686969   90.126389  \n",
       "4    -4.809713   73.033966  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8439, 77) (8439,)\n",
      "(3618, 77) (3618,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "pos    6202\n",
      "neg    5855\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "# Extracting the 'label' from the 'filename' column.\n",
    "# It appears the label is embedded in the filename and is the penultimate (second last) item when split by '_'.\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "\n",
    "# Checking the distribution of the labels.\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Dropping Unnecessary Columns and Splitting the Dataset:\n",
    "# The dataset column called filename is likely a unique identifier for each sample and not a feature we would use for modeling. Hence, we should remove it before feeding the data to our model. \n",
    "columns_to_drop = ['filename', 'label']  \n",
    "\n",
    "# Splitting the dataset into training and testing sets:\n",
    "# The split is done in a 70:30 ratio, and the random_state ensures reproducibility.\n",
    "# We still do train-test split here because the question specifies us to use 5-fold cross-validation on the training partition and not the whole dataset.\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=SEED)\n",
    "\n",
    "\n",
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # Dictionary Initializations\n",
    "    X_train_scaled_dict = {}  # Dictionary to store scaled training data\n",
    "    X_val_scaled_dict = {}    # Dictionary to store scaled validation data\n",
    "    y_train_dict = {}         # Dictionary to store training labels\n",
    "    y_val_dict = {}           # Dictionary to store validation labels\n",
    "\n",
    "    # Create a 5-fold cross-validation object with shuffling\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Loop through different batch sizes\n",
    "    for batch_size in parameters:\n",
    "        X_train_scaled_folds = []  # List to store scaled training data for each fold\n",
    "        X_val_scaled_folds = []    # List to store scaled validation data for each fold\n",
    "        y_train_folds = []         # List to store training labels for each fold\n",
    "        y_val_folds = []           # List to store validation labels for each fold\n",
    "\n",
    "        # Loop through each fold\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            X_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "            X_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
    "\n",
    "            # Scaling the data using StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "            # Append data to respective lists\n",
    "            X_train_scaled_folds.append(X_train_fold_scaled)\n",
    "            X_val_scaled_folds.append(X_val_fold_scaled)\n",
    "            y_train_folds.append(y_train_fold)\n",
    "            y_val_folds.append(y_val_fold)\n",
    "\n",
    "        # Store data for this batch size in dictionaries\n",
    "        X_train_scaled_dict[batch_size] = X_train_scaled_folds\n",
    "        X_val_scaled_dict[batch_size] = X_val_scaled_folds\n",
    "        y_train_dict[batch_size] = y_train_folds\n",
    "        y_val_dict[batch_size] = y_val_folds\n",
    "\n",
    "    # Return the dictionaries containing data for different batch sizes\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "set_seed(SEED)  # Set a specific random seed for reproducibility\n",
    "batch_sizes = [128, 256, 512, 1024]  # List of batch sizes to generate folds for\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import CustomDataset\n",
    "\n",
    "# Dictionaries to hold the DataLoaders for training and validation datasets for each batch size.\n",
    "set_seed(SEED)\n",
    "train_loaders_dict = {}\n",
    "val_loaders_dict = {}\n",
    "\n",
    "# Loop through each batch size we're considering\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    # Lists to store DataLoaders for the current batch size for each of the 5 folds\n",
    "    train_loaders = []\n",
    "    val_loaders = []\n",
    "\n",
    "    # Loop through each fold (0 through 4 for 5-fold CV)\n",
    "    for i in range(5):\n",
    "        \n",
    "        # Create a PyTorch Dataset for the training data for the current fold. The CustomDataset will convert our data into a format that PyTorch can work with.\n",
    "        train_dataset = CustomDataset(X_train_scaled_dict[batch_size][i], y_train_dict[batch_size][i])\n",
    "        \n",
    "        # Similarly, create a PyTorch Dataset for the validation data for the current fold.\n",
    "        val_dataset = CustomDataset(X_val_scaled_dict[batch_size][i], y_val_dict[batch_size][i])\n",
    "\n",
    "        # Create a DataLoader for the training dataset. This DataLoader will allow us to efficiently iterate over data in mini-batches of size 'batch_size'.\n",
    "        # We shuffle the training data to ensure the order is different each epoch.\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Create a DataLoader for the validation dataset. There's no need to shuffle validation data as we typically just evaluate performance on it.\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Append the created DataLoaders to our lists.\n",
    "        train_loaders.append(train_loader)\n",
    "        val_loaders.append(val_loader)\n",
    "\n",
    "    # Store the lists of DataLoaders in our dictionaries with the current batch size as the key. This way, when we need to access the DataLoader for a specific fold and batch size, we can easily retrieve it.\n",
    "    train_loaders_dict[batch_size] = train_loaders\n",
    "    val_loaders_dict[batch_size] = val_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting with batch_size: 128 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▊                                                                   | 17/100 [00:06<00:33,  2.48it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7079, Time: 0.3773 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▍                                                         | 29/100 [00:11<00:27,  2.56it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7618, Time: 0.3626 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▋                                                              | 23/100 [00:09<00:30,  2.52it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7423, Time: 0.3779 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▋                                                              | 23/100 [00:09<00:30,  2.52it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.7222, Time: 0.3775 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▊                                                           | 27/100 [00:10<00:28,  2.53it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7338, Time: 0.3686 seconds\n",
      "\n",
      "Batch size 128's Last Epoch - Mean Accuracy: 0.7336, Mean Time: 0.3728 seconds\n",
      "\n",
      "========== Starting with batch_size: 256 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▌                                                                  | 18/100 [00:05<00:24,  3.35it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7115, Time: 0.2833 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████                                                            | 26/100 [00:07<00:22,  3.31it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7382, Time: 0.2713 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▌                                                     | 34/100 [00:10<00:19,  3.35it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 35 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7376, Time: 0.2822 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▋                                                          | 28/100 [00:08<00:21,  3.38it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.718, Time: 0.2655 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▍                                                             | 24/100 [00:07<00:23,  3.27it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7356, Time: 0.2789 seconds\n",
      "\n",
      "Batch size 256's Last Epoch - Mean Accuracy: 0.7282, Mean Time: 0.2762 seconds\n",
      "\n",
      "========== Starting with batch_size: 512 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████▎                                                    | 35/100 [00:07<00:14,  4.43it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 36 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7453, Time: 0.2181 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▉                                                   | 37/100 [00:08<00:14,  4.38it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7346, Time: 0.2162 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▌                                                     | 34/100 [00:07<00:15,  4.38it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:00<00:20,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 35 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7281, Time: 0.2131 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▍                                                             | 24/100 [00:05<00:17,  4.36it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:00<00:20,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.6777, Time: 0.2017 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                        | 31/100 [00:06<00:15,  4.44it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:00<00:17,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7137, Time: 0.2113 seconds\n",
      "\n",
      "Batch size 512's Last Epoch - Mean Accuracy: 0.7199, Mean Time: 0.2121 seconds\n",
      "\n",
      "========== Starting with batch_size: 1024 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▊                                              | 43/100 [00:08<00:11,  5.14it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:00<00:17,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 44 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7186, Time: 0.3029 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▊                                                  | 38/100 [00:07<00:11,  5.20it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 39 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7233, Time: 0.1668 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████                                               | 42/100 [00:08<00:11,  5.25it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:00<00:18,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 43 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7382, Time: 0.1771 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▉                                                   | 37/100 [00:07<00:12,  5.05it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.6955, Time: 0.1783 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▋                                                          | 28/100 [00:05<00:14,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7184, Time: 0.1762 seconds\n",
      "\n",
      "Batch size 1024's Last Epoch - Mean Accuracy: 0.7188, Mean Time: 0.2003 seconds\n",
      "\n",
      "Mean Cross-Validation Accuracy On Final Epoch Against Different Batch Sizes:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Mean Cross-Validation Accuracy On Final Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.7336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.7188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Mean Cross-Validation Accuracy On Final Epoch\n",
       "0         128                                         0.7336\n",
       "1         256                                         0.7282\n",
       "2         512                                         0.7199\n",
       "3        1024                                         0.7188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "from common_utils import loss_fn, MLP, EarlyStopper, train_one_epoch, evaluate_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter_name):\n",
    "    \n",
    "    # Initialize dictionaries to store results\n",
    "    cross_validation_accuracies = {size: [] for size in batch_sizes}\n",
    "    cross_validation_times = {size: [] for size in batch_sizes}\n",
    "    \n",
    "    # Define the loss function for training\n",
    "    loss_function = loss_fn\n",
    "    \n",
    "    # Get the number of input features from the first batch of the first fold\n",
    "    no_features = X_train_scaled_dict[batch_sizes[0]][0].shape[1]\n",
    "    \n",
    "    # Define the number of hidden units in the neural network\n",
    "    no_hidden = 128\n",
    "    \n",
    "    # Define the number of output labels (binary classification)\n",
    "    no_labels = 1\n",
    "    \n",
    "    # Define other hyperparameters\n",
    "    num_folds = 5\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Iterate through each batch size\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"========== Starting with {hyperparameter_name}: {batch_size} ==========\")\n",
    "        \n",
    "        # Iterate through each fold (5-fold cross-validation)\n",
    "        for i in range(num_folds):\n",
    "            \n",
    "            # Create a neural network model\n",
    "            model = MLP(no_features, no_hidden, no_labels)\n",
    "            \n",
    "            # Define the optimizer with a specified learning rate\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Get the training and validation data loaders for the current batch size and fold\n",
    "            train_loader = train_loaders_dict[batch_size][i]\n",
    "            val_loader = val_loaders_dict[batch_size][i]\n",
    "            \n",
    "            # Initialize an EarlyStopper object to monitor early stopping\n",
    "            early_stopper = EarlyStopper(patience=3)\n",
    "            \n",
    "            # Loop through the specified number of training epochs\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Train the model for one epoch and compute the training loss\n",
    "                train_loss = train_one_epoch(model, train_loader, optimizer, loss_function)\n",
    "                \n",
    "                # Evaluate the model on the validation set and compute accuracy AND loss\n",
    "                val_accuracy, val_loss = evaluate_model(model, val_loader, loss_function)\n",
    "                \n",
    "                # Calculate the time taken for this epoch\n",
    "                end_time = time.time()\n",
    "                last_epoch_time = end_time - start_time\n",
    "                \n",
    "                # Check for early stopping based on validation loss\n",
    "                if early_stopper.early_stop(val_loss):\n",
    "                    print(f\"Early stopping at epoch {epoch + 1} during fold {i + 1}\")\n",
    "                    break\n",
    "\n",
    "            \n",
    "            # Store the time taken for the last epoch for this fold\n",
    "            cross_validation_times[batch_size].append(last_epoch_time)\n",
    "            \n",
    "            # Store the validation accuracy for this fold\n",
    "            cross_validation_accuracies[batch_size].append(val_accuracy)\n",
    "            \n",
    "            # Print the results for this fold\n",
    "            print(f\"Fold {i + 1} Last Epoch - Accuracy: {round(val_accuracy,4)}, Time: {round(last_epoch_time,4)} seconds\")\n",
    "        \n",
    "        print()\n",
    "        # Calculate and print the mean cross-validation accuracy + mean time taken for last epoch for this batch size\n",
    "        mean_accuracy = sum(cross_validation_accuracies[batch_size]) / len(cross_validation_accuracies[batch_size])\n",
    "        mean_time = sum(cross_validation_times[batch_size]) / len(cross_validation_times[batch_size])\n",
    "        print(f\"Batch size {batch_size}'s Last Epoch - Mean Accuracy: {round(mean_accuracy,4)}, Mean Time: {round(mean_time,4)} seconds\")\n",
    "        print()\n",
    "        \n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n",
    "\n",
    "# Prepare for plotting\n",
    "batch_sizes_list = list(cross_validation_accuracies.keys())\n",
    "mean_cv_accuracies = [round(sum(cross_validation_accuracies[batch_size]) / len(cross_validation_accuracies[batch_size]),4) for batch_size in batch_sizes_list]\n",
    "\n",
    "# Create a dataframe for mean cross validation accuracies against batch sizes\n",
    "cv_accuracies_df = pd.DataFrame({\n",
    "    'Batch Size': batch_sizes_list,\n",
    "    'Mean Cross-Validation Accuracy On Final Epoch': mean_cv_accuracies\n",
    "})\n",
    "\n",
    "print(\"Mean Cross-Validation Accuracy On Final Epoch Against Different Batch Sizes:\")\n",
    "print()\n",
    "display(cv_accuracies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Plot mean cross-validation accuracies on the final epoch for different batch sizes\n",
    "plt.scatter(batch_sizes_list, mean_cv_accuracies, marker='x')\n",
    "plt.xlabel('Batch Sizes')\n",
    "plt.ylabel('Mean Cross-Validation Accuracy')\n",
    "plt.title('Mean Cross-Validation Accuracy On Final Epoch vs Batch Size')\n",
    "plt.xticks(batch_sizes_list)\n",
    "\n",
    "# Add labels to each data point\n",
    "for i, txt in enumerate(mean_cv_accuracies):\n",
    "    if i == 2 or i == 3:\n",
    "        plt.text(batch_sizes_list[i] - 10, mean_cv_accuracies[i] + 0.0012, round(txt, 4), ha='center')  \n",
    "    else:\n",
    "        plt.text(batch_sizes_list[i] + 10, mean_cv_accuracies[i] - 0.0012, round(txt, 4), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time Taken to Train the Network on the Last Epoch Across 5 Folds Against Different Batch Sizes:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Mean Time Taken for Last Epoch Across 5 Folds (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.3728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Mean Time Taken for Last Epoch Across 5 Folds (seconds)\n",
       "0         128                                             0.3728      \n",
       "1         256                                             0.2762      \n",
       "2         512                                             0.2121      \n",
       "3        1024                                             0.2003      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Please note that the next time you run this notebook cell, the results will be different as time taken depends on CPU speed and other factors.\n",
    "\n",
    "# Calculate mean time for the last epoch for each batch size\n",
    "mean_last_epoch_times_list = [round(sum(cross_validation_times[batch_size]) / len(cross_validation_times[batch_size]),4) for batch_size in batch_sizes_list]\n",
    "\n",
    "# Create a table of time taken to train the network on the last epoch against different batch sizes\n",
    "time_df = pd.DataFrame({\n",
    "    'Batch Size': batch_sizes_list,\n",
    "    'Mean Time Taken for Last Epoch Across 5 Folds (seconds)': mean_last_epoch_times_list\n",
    "})\n",
    "\n",
    "print(\"Mean Time Taken to Train the Network on the Last Epoch Across 5 Folds Against Different Batch Sizes:\")\n",
    "print()\n",
    "display(time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal batch size: 256\n",
      "\n",
      "Reason: \n",
      "\n",
      "Given the balance of accuracy and speed, the Batch Size of 256 emerges as the optimal choice.\n",
      "\n",
      "Selection of Optimal Batch Size:\n",
      "\n",
      "    • Selecting the appropriate batch size is a crucial step in the optimization of neural networks. The goal is to find an equilibrium that harmonizes both computational efficiency \n",
      "    and model accuracy. Intuitively, as batch size increases, training tends to be swifter due to enhanced parallelism and optimized matrix operations, resulting in a higher throughput \n",
      "    of computations. However, excessively large batch sizes may reduce the stochastic nature of gradient descent, potentially leading to a compromise in accuracy as we can see in the \n",
      "    results above. Additionally, it is also important to note that the trends are not definitive for the entire dataset as we are only calculating the mean values of the last epoch over the 5 folds\n",
      "    for each batch size. Thus, the results may vary if we take the mean values of all the epochs instead.\n",
      "\n",
      "From the data:\n",
      "\n",
      "    • Batch Size of 128: This size is the most accurate, coming in at 0.7336. However, this heightened accuracy comes at the cost of time, as it is the slowest,taking about 0.3686 seconds.\n",
      "\n",
      "    • Batch Size of 256: Presents itself as the optimal choice. Its accuracy is the second highest at 0.7282 by quite a large margin. Moreover, its efficiency shines through, clocking in a time of \n",
      "    0.2762 seconds. It offers the best trade-off between performance and speed.\n",
      "\n",
      "    • Batch Sizes of 512 and 1024: As the batch sizes increase, we note a clear decline in accuracy. The batch size of 512 is faster than the first two at 0.2121 seconds, but its \n",
      "    accuracy drops to 0.7186. Similarly, a batch size of 1024 is the fastest at 0.2003 seconds but has a lowest accuracy of 0.7188.\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "    • While the batch size of 128 has a competitive accuracy, the performance of 256 with a higher accuracy and reasonable computation time stands out. The difference in accuracy \n",
      "    between 128 and 256 is quite large and the increase in efficiency with 256 is significant. Furthermore, as we increase the batch size beyond this point, the reductions in time do not \n",
      "    compensate for the drops in accuracy, particularly at 512 and 1024. Thus, the batch size of 256 provides the most balanced outcome in the context of our data, combining \n",
      "    together swift training with robust performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 256\n",
    "reason = '''\n",
    "\n",
    "Given the balance of accuracy and speed, the Batch Size of 256 emerges as the optimal choice.\n",
    "\n",
    "Selection of Optimal Batch Size:\n",
    "\n",
    "    • Selecting the appropriate batch size is a crucial step in the optimization of neural networks. The goal is to find an equilibrium that harmonizes both computational efficiency \n",
    "    and model accuracy. Intuitively, as batch size increases, training tends to be swifter due to enhanced parallelism and optimized matrix operations, resulting in a higher throughput \n",
    "    of computations. However, excessively large batch sizes may reduce the stochastic nature of gradient descent, potentially leading to a compromise in accuracy as we can see in the \n",
    "    results above. Additionally, it is also important to note that the trends are not definitive for the entire dataset as we are only calculating the mean values of the last epoch over the 5 folds\n",
    "    for each batch size. Thus, the results may vary if we take the mean values of all the epochs instead.\n",
    "\n",
    "From the data:\n",
    "\n",
    "    • Batch Size of 128: This size is the most accurate, coming in at 0.7336. However, this heightened accuracy comes at the cost of time, as it is the slowest,taking about 0.3686 seconds.\n",
    "\n",
    "    • Batch Size of 256: Presents itself as the optimal choice. Its accuracy is the second highest at 0.7282 by quite a large margin. Moreover, its efficiency shines through, clocking in a time of \n",
    "    0.2762 seconds. It offers the best trade-off between performance and speed.\n",
    "\n",
    "    • Batch Sizes of 512 and 1024: As the batch sizes increase, we note a clear decline in accuracy. The batch size of 512 is faster than the first two at 0.2121 seconds, but its \n",
    "    accuracy drops to 0.7186. Similarly, a batch size of 1024 is the fastest at 0.2003 seconds but has a lowest accuracy of 0.7188.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "    • While the batch size of 128 has a competitive accuracy, the performance of 256 with a higher accuracy and reasonable computation time stands out. The difference in accuracy \n",
    "    between 128 and 256 is quite large and the increase in efficiency with 256 is significant. Furthermore, as we increase the batch size beyond this point, the reductions in time do not \n",
    "    compensate for the drops in accuracy, particularly at 512 and 1024. Thus, the batch size of 256 provides the most balanced outcome in the context of our data, combining \n",
    "    together swift training with robust performance.\n",
    "'''\n",
    "\n",
    "print(f\"Optimal batch size: {optimal_batch_size}\")\n",
    "print()\n",
    "print(f\"Reason: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
